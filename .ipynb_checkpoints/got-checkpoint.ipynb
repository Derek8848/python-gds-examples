{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neo4j Graph Data Science Starter Kit\n",
    "This notebook acts as a simple starter kit for using the Neo4j GDS library from Python.\n",
    "It contains code fragments to do the following:\n",
    "1. Set up a connection to Neo4j and read/write data.\n",
    "3. Create graph projections to run your algorithm on.\n",
    "4. Run algorithms and stream back results to Neo4j.\n",
    "\n",
    "This example uses the Game of Thrones dataset as present in the Neo4j graph data science sandbox. You can get your own for free here:\n",
    "https://sandbox.neo4j.com/login?usecase=graph-data-science\n",
    "\n",
    "If you want to import this dataset into your local instance, please clo\n",
    "https://github.com/Derek8848/python-gds-examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Setting up the Neo4j Driver\n",
    "Enter your own Neo4j credentials here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"bolt://192.168.2.30:7687/got\"\n",
    "user = \"neo4j\"\n",
    "password = \"neo\" \n",
    "dbname = 'got'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "driver = GraphDatabase.driver(url, auth=(user, password))\n",
    "neo4j = driver.session(database=dbname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example - Reading Neo4j results using the driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    name   age\n",
      "0    Gunthor son of Gurn   NaN\n",
      "1  High Septon (fat_one)   NaN\n",
      "2        Jaime Lannister  39.0\n",
      "3         Gregor Clegane  35.0\n",
      "4            Andros Brax   NaN\n",
      "5           Roose Bolton  45.0\n",
      "6         Wylis Manderly  53.0\n",
      "7          Medger Cerwyn   NaN\n",
      "8       Harrion Karstark   NaN\n",
      "9         Halys Hornwood   NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "result = neo4j.run('MATCH (n:Person) RETURN n.name AS name, n.age as age LIMIT 10')\n",
    "df = pd.DataFrame(result.data())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Creating a graph projection\n",
    "As an example, we want to analyze which people are most influential using the PageRank algorithm.\n",
    "\n",
    "First, create a graph projection `interactions` that contains only the pattern we are interested in: `(:Person)-[:INTERACTS]->(:Person)`. \n",
    "\n",
    "Then, go through the following steps:\n",
    "- Check if we have enough memory to generate it.\n",
    "- Check if the graph projection already exists, if so, delete it.\n",
    "- Create the graph projection.\n",
    "\n",
    "\n",
    "### Estimating the required size of the projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated: 2166 nodes, 3907 relationships, 282 KiB  memory required.\n"
     ]
    }
   ],
   "source": [
    "# Run the Cypher query\n",
    "result = neo4j.run(\"\"\"\n",
    "CALL gds.graph.create.cypher.estimate(\n",
    "    'MATCH (p) WHERE p:Person RETURN id(p) as id',\n",
    "    'MATCH (p)-[:INTERACTS]->(p2:Person) RETURN id(p) AS source, id(p2) AS target')\n",
    "\"\"\")\n",
    "\n",
    "# Print the results\n",
    "row = result.single()\n",
    "print(\"Estimated:\", row['nodeCount'], \"nodes,\", row['relationshipCount'], \"relationships,\", row['requiredMemory'],\" memory required.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear existing in-memory graphs (if they exist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'message': 'interactions-all-books was dropped.'}]\n"
     ]
    }
   ],
   "source": [
    "import pprint \n",
    "\n",
    "# This query drops the projected graph if it already exists, else it returns 'None'.\n",
    "result = neo4j.run(\"\"\"\n",
    "CALL gds.graph.exists($name) YIELD exists\n",
    "WHERE exists\n",
    "CALL gds.graph.drop($name) YIELD graphName\n",
    "RETURN graphName + \" was dropped.\" as message\n",
    "\"\"\", name = 'interactions-all-books')\n",
    "\n",
    "# Print the results\n",
    "pprint.pprint(result.data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the new graph projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interactions-all-books - 2166 nodes, 3907 relationships, 32  ms to create the projection.\n"
     ]
    }
   ],
   "source": [
    "# Create a weighted Cypher projection graph of (Person)-[:INTERACTS]->(:Person)\n",
    "result = neo4j.run(\"\"\"\n",
    "CALL gds.graph.create.cypher(\n",
    "    'interactions-all-books',\n",
    "    'MATCH (p) WHERE p:Person RETURN id(p) as id',\n",
    "    'MATCH (p)-[i:INTERACTS]->(p2:Person) RETURN id(p) AS source, i.weight as weight, id(p2) AS target')\n",
    "\"\"\")\n",
    "#result = neo4j.run(\"\"\"\n",
    "#CALL gds.graph.create('interactions-all-books', 'Person', {\n",
    "#  INTERACTS: {\n",
    "#    orientation: 'UNDIRECTED'\n",
    " # }\n",
    "#})\n",
    "#\"\"\")\n",
    "\n",
    "# Print the results\n",
    "row = result.single()\n",
    "print(row['graphName'],\"-\", row['nodeCount'], \"nodes,\", row['relationshipCount'], \"relationships,\", row['createMillis'],\" ms to create the projection.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Running graph algorithms\n",
    "Now that we have our graph project, we're ready to run the algorithm!\n",
    "\n",
    "As always, best practice is to first check if we have enough memory for running the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 KiB  memory required to run the algorithm.\n"
     ]
    }
   ],
   "source": [
    "result = neo4j.run(\"\"\"\n",
    "CALL gds.pageRank.stream.estimate('interactions-all-books',  { relationshipWeightProperty: 'weight' })\n",
    "\"\"\")\n",
    "\n",
    "print(result.single()['requiredMemory'], ' memory required to run the algorithm.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the algorithm (stream mode)\n",
    "First, use 'stream' mode to inspect the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              character      score\n",
      "0      Tyrion Lannister  16.006419\n",
      "1       Tywin Lannister   8.975132\n",
      "2                 Varys   8.487425\n",
      "3     Stannis Baratheon   8.152840\n",
      "4         Theon Greyjoy   5.456873\n",
      "...                 ...        ...\n",
      "2161       Ryger Rivers   0.150000\n",
      "2162        Rupert Brax   0.150000\n",
      "2163  Rymolf Stormdrunk   0.150000\n",
      "2164      Ryon Allyrion   0.150000\n",
      "2165       Sarella Sand   0.150000\n",
      "\n",
      "[2166 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "result = neo4j.run(\"\"\"\n",
    "CALL gds.pageRank.stream('interactions-all-books', { relationshipWeightProperty: 'weight'}) \n",
    "YIELD nodeId, score\n",
    "RETURN gds.util.asNode(nodeId).name as character, score \n",
    "ORDER BY score DESC\n",
    "\"\"\")\n",
    "\n",
    "df = pd.DataFrame(result.data())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the algorithm (write mode)\n",
    "Then, use 'write' mode to write the results back to the Neo4j database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'centralityDistribution': {'max': 16.006468772888184,\n",
      "                             'mean': 0.22740707106867655,\n",
      "                             'min': 0.14999961853027344,\n",
      "                             'p50': 0.14999961853027344,\n",
      "                             'p75': 0.15213584899902344,\n",
      "                             'p90': 0.2666940689086914,\n",
      "                             'p95': 0.42917728424072266,\n",
      "                             'p99': 1.382765769958496,\n",
      "                             'p999': 8.487425804138184},\n",
      "  'computeMillis': 33,\n",
      "  'configuration': {'cacheWeights': False,\n",
      "                    'concurrency': 4,\n",
      "                    'dampingFactor': 0.85,\n",
      "                    'maxIterations': 20,\n",
      "                    'nodeLabels': ['*'],\n",
      "                    'relationshipTypes': ['*'],\n",
      "                    'relationshipWeightProperty': 'weight',\n",
      "                    'scaler': 'NONE',\n",
      "                    'sourceNodes': [],\n",
      "                    'sudo': False,\n",
      "                    'tolerance': 1e-07,\n",
      "                    'username': None,\n",
      "                    'writeConcurrency': 4,\n",
      "                    'writeProperty': 'pagerank-all-books'},\n",
      "  'createMillis': 0,\n",
      "  'didConverge': True,\n",
      "  'nodePropertiesWritten': 2166,\n",
      "  'postProcessingMillis': 36,\n",
      "  'ranIterations': 15,\n",
      "  'writeMillis': 27}]\n"
     ]
    }
   ],
   "source": [
    "result = neo4j.run(\"CALL gds.pageRank.write('interactions-all-books', { writeProperty: 'pagerank-all-books', relationshipWeightProperty: 'weight' })\")\n",
    "\n",
    "pprint.pprint(result.data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using graph features in ML\n",
    "Now that we have the PageRank of each of the people in the Game of Thrones dataset, lets use it as a predictor variable.\n",
    "\n",
    "We're going to predict whether a character will die based on `house`, `age`, `gender`, `culture`,  and `pageRank` of the corresponding node.\n",
    "\n",
    "To prevent data leakage between the train/test sets, we'll need to calculate two different pageranks: \n",
    "- `pagerank_train` - the pagerank based on interactions in books 1-4.\n",
    "- `pagerank_test` - the pagerank based on the interactions in book 5.\n",
    "\n",
    "Then, we can train the model with only data derived from the first four books.\n",
    "\n",
    "We already have the pagerank for the interactions in books 1 to 5 (the test data), so we quickly calculate them for books 1-4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training graph projection created and algorithm executed. Pagerank for interactions in books 1-4 written to graph.\n"
     ]
    }
   ],
   "source": [
    "# Shorthand for everything we did in steps 2 & 3. This time, only look at interactions in the first four books.\n",
    "neo4j.run(\"CALL gds.graph.exists($name) YIELD exists WHERE exists CALL gds.graph.drop($name) YIELD graphName RETURN graphName + ' was dropped.' as message\", name = 'interactions-book-1-4')\n",
    "neo4j.run(\"CALL gds.graph.create.cypher('interactions-book-1-4', 'MATCH (p) WHERE p:Person RETURN id(p) as id', 'MATCH (p)-[i:INTERACTS]->(p2:Person) WHERE i.book <= 4 RETURN id(p) AS source, i.weight as weight, id(p2) AS target') \")\n",
    "neo4j.run(\"CALL gds.pageRank.write('interactions-book-1-4', { writeProperty: 'pagerank-book-1-4', relationshipWeightProperty: 'weight' })\")\n",
    "\n",
    "print(\"Training graph projection created and algorithm executed. Pagerank for interactions in books 1-4 written to graph.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Loading the features from Neo4j\n",
    "Now that we have all the input data for our model, load data from Neo4j into a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               name  age  gender   culture          house  pagerank_train  \\\n",
      "0  Tyrion Lannister   32    male      None      Lannister       14.491701   \n",
      "1   Tywin Lannister   58    male      None      Lannister        9.041644   \n",
      "2       Sansa Stark   19  female  northmen          Stark        4.637839   \n",
      "3       Walder Frey   97    male  rivermen           Frey        4.487632   \n",
      "4     Samwell Tarly   22    male  westeros  Night's Watch        3.617952   \n",
      "\n",
      "   pagerank_test  is_dead  \n",
      "0      16.006419    False  \n",
      "1       8.975132     True  \n",
      "2       4.504770    False  \n",
      "3       4.160119    False  \n",
      "4       3.380056    False  \n"
     ]
    }
   ],
   "source": [
    "# Consider only the characters that have a defined age.\n",
    "result = neo4j.run(\n",
    "\"\"\"\n",
    "MATCH (p:Person)\n",
    "WHERE p.age >= 0\n",
    "MATCH (p)-[:BELONGS_TO]->(h:House) \n",
    "OPTIONAL MATCH (p)-[:MEMBER_OF_CULTURE]->(c:Culture) \n",
    "OPTIONAL MATCH (p)-[:APPEARED_IN]->(b:Book)\n",
    "RETURN p.name as name, p.age as age, p.gender as gender, \n",
    "       collect(c.name)[0] as culture, collect(h.name)[0] as house, \n",
    "       p.`pagerank-book-1-4` as pagerank_train,\n",
    "       p.`pagerank-all-books` as pagerank_test, (p:Dead) as is_dead \n",
    "       ORDER BY pagerank_train DESC\n",
    "\"\"\")\n",
    "\n",
    "df = pd.DataFrame(result.data())\n",
    "print(df[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4.2 Process the data into a format the model expects\n",
    "Now we transform the data into a format that the RandomForestClassifier can work with. This requires a couple of transformations:\n",
    "- We convert our result variable (True/False) into (0/1).\n",
    "- We create dummy variables for categorical values.\n",
    "- We scale the numeric variables to a 0-1 range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sj/f31y2gh149z_28ld6s8zdh3r0000gn/T/ipykernel_27766/292600101.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Select the right result columns. Make dummy variables, factorize non-numeric columns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgenders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gender'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcultures\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'culture'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Select the right result columns. Make dummy variables, factorize non-numeric columns.\n",
    "genders = pd.get_dummies(df['gender'])\n",
    "cultures =  pd.get_dummies(df['culture'])\n",
    "houses = pd.get_dummies(df['house'])\n",
    "dead  = pd.DataFrame(pd.factorize(df['is_dead'])[0])\n",
    "age = df['age']\n",
    "pagerank_train = df['pagerank_train']\n",
    "pagerank_test = df['pagerank_test']\n",
    "\n",
    "# Construct the new data frame and scale.\n",
    "data = pd.concat([houses, cultures, genders, age, pagerank_train, pagerank_test, dead], axis=1) \n",
    "data.columns = houses.columns.values.tolist() + cultures.columns.values.tolist()  + genders.columns.values.tolist() + ['age', 'pagerank_train', 'pagerank_test','is_dead']\n",
    "scaler = MinMaxScaler() \n",
    "scaled_values = scaler.fit_transform(data) \n",
    "data.loc[:,:] = scaled_values\n",
    "\n",
    "print(data[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Train/test split\n",
    "Lets see how much we can boost the model accuracy by using `pagerank` as a feature.\n",
    "\n",
    "We'll have to do a comparison - train two models  and compare their AUC scores:\n",
    "1. A RandomForestClassifier that uses `[gender, house, age, culture]` to predict `is_dead`:\n",
    "2. A RandomForestClassifier that uses `[gender, house, age, culture, pagerank]` to predict `is_dead`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sj/f31y2gh149z_28ld6s8zdh3r0000gn/T/ipykernel_96847/761590921.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_dead'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# The original model uses [gender, house, age, culture] to predict [is_dead].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = data['is_dead']\n",
    "y_train, y_test =  train_test_split(y, random_state=0, stratify=y, test_size=0.2)\n",
    "\n",
    "# The original model uses [gender, house, age, culture] to predict [is_dead].\n",
    "X = data.iloc[:, 0:len(data.columns)-3]\n",
    "X_train = X.iloc[y_train.index]\n",
    "X_test = X.iloc[y_test.index]\n",
    "\n",
    "# The new model uses [gender, house, age, culture, pagerank] to predict [is_dead].\n",
    "# The training data uses the pagerank for interactions in the first four books: [pagerank_train].\n",
    "# The test data uses the pagerank for interactions in all books: [pagerank_test]\n",
    "X2_train = data.iloc[:, 0:len(data.columns)-2]\n",
    "X2_test = data.iloc[:, list(range(0,len(data.columns)-3)) + [len(data.columns)-2]]\n",
    "X2_train = X2_train.iloc[y_train.index]\n",
    "X2_test = X2_test.iloc[y_test.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Train and compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(class_weight=\"balanced\", n_estimators=10)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Score without pagerank: \", roc_auc_score(y_test, y_score=clf.predict(X_test)))\n",
    "\n",
    "clf.fit(X2_train, y_train)\n",
    "print(\"Score with pagerank: \", roc_auc_score(y_test, y_score=clf.predict(X2_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're seeing a slight improvement when adding our new feature! - however, keep in mind this dataset is *really tiny*: it's naturally very subceptible to randomness in the classifier and choice of train/test split. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next?\n",
    "to learn more about the different execution modes of algorithms:\n",
    "https://neo4j.com/docs/graph-data-science/current/common-usage/running-algos/\n",
    "\n",
    "To speed up your process, consider looking into native projections:\n",
    "https://neo4j.com/docs/graph-data-science/current/management-ops/native-projection/.\n",
    "\n",
    "Read the docs on other algorithms, tips for modeling your data, and algo configurations:\n",
    "https://neo4j.com/docs/graph-data-science/current/introduction/\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
